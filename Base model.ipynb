{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e54c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (1.8.3)\n",
      "Requirement already satisfied: black>=24.10.0 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from kaggle) (26.1.0)\n",
      "Requirement already satisfied: bleach in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from kaggle) (6.3.0)\n",
      "Requirement already satisfied: kagglesdk<1.0,>=0.1.14 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from kaggle) (0.1.15)\n",
      "Requirement already satisfied: mypy>=1.15.0 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from kaggle) (1.19.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from kaggle) (25.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from kaggle) (6.33.5)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from kaggle) (4.67.2)\n",
      "Requirement already satisfied: types-requests in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from kaggle) (2.32.4.20260107)\n",
      "Requirement already satisfied: types-tqdm in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from kaggle) (4.67.0.20250809)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from kaggle) (2.6.3)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from black>=24.10.0->kaggle) (8.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from black>=24.10.0->kaggle) (1.1.0)\n",
      "Requirement already satisfied: pathspec>=1.0.0 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from black>=24.10.0->kaggle) (1.0.4)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from black>=24.10.0->kaggle) (4.5.0)\n",
      "Requirement already satisfied: pytokens>=0.3.0 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from black>=24.10.0->kaggle) (0.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from click>=8.0.0->black>=24.10.0->kaggle) (0.4.6)\n",
      "Requirement already satisfied: typing_extensions>=4.6.0 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from mypy>=1.15.0->kaggle) (4.15.0)\n",
      "Requirement already satisfied: librt>=0.6.2 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from mypy>=1.15.0->kaggle) (0.7.8)\n",
      "Requirement already satisfied: webencodings in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from requests->kaggle) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from requests->kaggle) (3.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from requests->kaggle) (2026.1.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (2.3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: polars in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (1.38.1)\n",
      "Requirement already satisfied: polars-runtime-32==1.38.1 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from polars) (1.38.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (23.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from xgboost) (2.3.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\python\\pythoncore-3.14-64\\lib\\site-packages (from xgboost) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in c:\\users\\user\\appdata\\roaming\\python\\python314\\site-packages (7.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install kaggle\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install polars\n",
    "%pip install pyarrow\n",
    "%pip install seaborn\n",
    "%pip install matplotlib\n",
    "%pip install xgboost\n",
    "%pip install psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58ef17",
   "metadata": {},
   "source": [
    "# Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "409b39e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "class Pipeline: \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        null_threshold: float = 0.7,\n",
    "        high_card_threshold: int = 200,\n",
    "    ):\n",
    "        self.data_path = data_path\n",
    "        self.null_threshold = null_threshold\n",
    "        self.high_card_threshold = high_card_threshold\n",
    "        self.feature_columns = None\n",
    "        \n",
    "    def load_data(self, filename):\n",
    "        df = pl.read_parquet(f\"{self.data_path}/{filename}\")\n",
    "        return df\n",
    "    \n",
    "    def set_table_dtypes(self, df):\n",
    "        cast_exprs = []\n",
    "\n",
    "        for col in df.columns:\n",
    "\n",
    "            if col in [\"case_id\", \"WEEK_NUM\", \"num_group1\", \"num_group2\"]:\n",
    "                cast_exprs.append(pl.col(col).cast(pl.Int64))\n",
    "\n",
    "            elif col == \"date_decision\":\n",
    "                cast_exprs.append(pl.col(col).cast(pl.Date))\n",
    "\n",
    "            elif col.endswith((\"P\", \"A\")):\n",
    "                cast_exprs.append(pl.col(col).cast(pl.Float32))  # use Float32 for memory\n",
    "\n",
    "            elif col.endswith(\"M\"):\n",
    "                cast_exprs.append(pl.col(col).cast(pl.Utf8))\n",
    "\n",
    "            elif col.endswith(\"D\"):\n",
    "                cast_exprs.append(pl.col(col).cast(pl.Date))\n",
    "\n",
    "        return df.with_columns(cast_exprs)\n",
    "    \n",
    "    def handle_dates(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        \n",
    "        if \"date_decision\" not in df.columns:\n",
    "            return df\n",
    "        \n",
    "        date_cols = [c for c in df.columns if c.endswith(\"D\")]\n",
    "\n",
    "        df = df.with_columns([\n",
    "            (\n",
    "                pl.col(col) - pl.col(\"date_decision\")\n",
    "            )\n",
    "            .dt.total_days()\n",
    "            .cast(pl.Float32)\n",
    "            .alias(col)\n",
    "            for col in date_cols\n",
    "        ])\n",
    "\n",
    "        # Drop decision date & MONTH if exists\n",
    "        drop_cols = [c for c in [\"date_decision\", \"MONTH\"] if c in df.columns]\n",
    "        if drop_cols:\n",
    "            df = df.drop(drop_cols)\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Remove high-null columns and remove high-cardinality string columns\n",
    "    def filter_columns(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        cols_to_drop = []\n",
    "\n",
    "        protected = [\"target\", \"case_id\", \"WEEK_NUM\"]\n",
    "\n",
    "        for col in df.columns:\n",
    "\n",
    "            if col in protected:\n",
    "                continue\n",
    "\n",
    "            # High null ratio filtering\n",
    "            null_ratio = (\n",
    "                df.select(pl.col(col).null_count() / pl.count()).item()\n",
    "            )\n",
    "\n",
    "            if null_ratio > self.null_threshold:\n",
    "                cols_to_drop.append(col)\n",
    "                continue\n",
    "\n",
    "            # String cardinality filtering\n",
    "            if df.schema[col] == pl.Utf8:\n",
    "                n_unique = df.select(pl.col(col).n_unique()).item()\n",
    "\n",
    "                if n_unique == 1 or n_unique > self.high_card_threshold:\n",
    "                    cols_to_drop.append(col)\n",
    "\n",
    "        if cols_to_drop:\n",
    "            df = df.drop(cols_to_drop)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def preprocess(self, filename: str) -> pl.DataFrame:\n",
    "        df = self.load_data(filename)\n",
    "        df = self.set_table_dtypes(df)\n",
    "        df = self.handle_dates(df)\n",
    "        df = self.filter_columns(df)\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def fit(self, train_filename: str):\n",
    "\n",
    "        df = self.preprocess(train_filename)\n",
    "\n",
    "        self.y = df[\"target\"].to_numpy()\n",
    "        df = df.drop(\"target\")\n",
    "\n",
    "        self.feature_columns = df.columns\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def transform(self, test_filename: str):\n",
    "\n",
    "        df = self.preprocess(test_filename)\n",
    "\n",
    "        # Align to train feature order\n",
    "        df = df.select(self.feature_columns)\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8b8196",
   "metadata": {},
   "source": [
    "# Create aggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65b103c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aggregator:\n",
    "    def num_expr(df, prefix):\n",
    "        cols = [c for c in df.columns if c.endswith((\"P\", \"A\"))]\n",
    "\n",
    "        return (\n",
    "            [pl.col(c).max().alias(f\"{prefix}_max_{c}\") for c in cols] +\n",
    "            [pl.col(c).mean().alias(f\"{prefix}_mean_{c}\") for c in cols] +\n",
    "            [pl.col(c).last().alias(f\"{prefix}_last_{c}\") for c in cols]\n",
    "        )\n",
    "    \n",
    "    def date_expr(df, prefix):\n",
    "        cols = [c for c in df.columns if c.endswith(\"D\")]\n",
    "\n",
    "        return (\n",
    "            [pl.col(c).max().alias(f\"{prefix}_max_{c}\") for c in cols] +\n",
    "            [pl.col(c).last().alias(f\"{prefix}_last_{c}\") for c in cols]\n",
    "        )\n",
    "    \n",
    "    def str_expr(df, prefix):\n",
    "        cols = [c for c in df.columns if c.endswith(\"M\")]\n",
    "\n",
    "        return (\n",
    "            [pl.col(c).last().alias(f\"{prefix}_last_{c}\") for c in cols]\n",
    "        )\n",
    "    \n",
    "    def count_expr(df, prefix):\n",
    "        cols = [c for c in df.columns if \"num_group\" in c]\n",
    "\n",
    "        return (\n",
    "            [pl.col(c).max().alias(f\"{prefix}_max_{c}\") for c in cols] +\n",
    "            [pl.col(c).last().alias(f\"{prefix}_last_{c}\") for c in cols]\n",
    "        )\n",
    "    \n",
    "    def other_expr(df, prefix):\n",
    "        cols = [c for c in df.columns if c.endswith((\"T\", \"L\"))]\n",
    "\n",
    "        return (\n",
    "            [pl.col(c).max().alias(f\"{prefix}_max_{c}\") for c in cols] +\n",
    "            [pl.col(c).last().alias(f\"{prefix}_last_{c}\") for c in cols]\n",
    "        )\n",
    "    \n",
    "    def get_exprs(df, prefix):\n",
    "\n",
    "        return (\n",
    "            Aggregator.num_expr(df, prefix) +\n",
    "            Aggregator.date_expr(df, prefix) +\n",
    "            Aggregator.str_expr(df, prefix) +\n",
    "            Aggregator.other_expr(df, prefix) +\n",
    "            Aggregator.count_expr(df, prefix)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9cd587",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82a902ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"home_credit_data/parquet_files/train\")\n",
    "\n",
    "TABLES = {\n",
    "    \"base\": DATA_DIR / \"train_base.parquet\",\n",
    "    \"static_0_0\": DATA_DIR / \"train_static_0_0.parquet\",\n",
    "    \"static_0_1\": DATA_DIR / \"train_static_0_1.parquet\",\n",
    "    \"static_cb_0\": DATA_DIR / \"train_static_cb_0.parquet\",\n",
    "    \"person_1\": DATA_DIR / \"train_person_1.parquet\",\n",
    "    \"person_2\": DATA_DIR / \"train_person_2.parquet\",\n",
    "    \"applprev_1_0\": DATA_DIR / \"train_applprev_1_0.parquet\",\n",
    "    \"applprev_1_1\": DATA_DIR / \"train_applprev_1_1.parquet\",\n",
    "    \"applprev_2\": DATA_DIR / \"train_applprev_2.parquet\",\n",
    "    \"credit_bureau_a_1_0\": DATA_DIR / \"train_credit_bureau_a_1_0.parquet\",\n",
    "    \"credit_bureau_a_1_1\": DATA_DIR / \"train_credit_bureau_a_1_1.parquet\",\n",
    "    \"credit_bureau_a_1_2\": DATA_DIR / \"train_credit_bureau_a_1_2.parquet\",\n",
    "    \"credit_bureau_a_1_3\": DATA_DIR / \"train_credit_bureau_a_1_3.parquet\",\n",
    "    \"credit_bureau_a_2_0\": DATA_DIR / \"train_credit_bureau_a_2_0.parquet\",\n",
    "    \"credit_bureau_a_2_1\": DATA_DIR / \"train_credit_bureau_a_2_1.parquet\",\n",
    "    \"credit_bureau_a_2_2\": DATA_DIR / \"train_credit_bureau_a_2_2.parquet\",\n",
    "    \"credit_bureau_a_2_3\": DATA_DIR / \"train_credit_bureau_a_2_3.parquet\",\n",
    "    \"credit_bureau_a_2_4\": DATA_DIR / \"train_credit_bureau_a_2_4.parquet\",\n",
    "    \"credit_bureau_a_2_5\": DATA_DIR / \"train_credit_bureau_a_2_5.parquet\",\n",
    "    \"credit_bureau_a_2_6\": DATA_DIR / \"train_credit_bureau_a_2_6.parquet\",\n",
    "    \"credit_bureau_a_2_7\": DATA_DIR / \"train_credit_bureau_a_2_7.parquet\",\n",
    "    \"credit_bureau_a_2_8\": DATA_DIR / \"train_credit_bureau_a_2_8.parquet\",\n",
    "    \"credit_bureau_a_2_9\": DATA_DIR / \"train_credit_bureau_a_2_9.parquet\",\n",
    "    \"credit_bureau_a_2_10\": DATA_DIR / \"train_credit_bureau_a_2_10.parquet\",\n",
    "    \"credit_bureau_b_1\": DATA_DIR / \"train_credit_bureau_b_1.parquet\",\n",
    "    \"credit_bureau_b_2\": DATA_DIR / \"train_credit_bureau_b_2.parquet\",\n",
    "    \"debitcard_1\": DATA_DIR / \"train_debitcard_1.parquet\",\n",
    "    \"deposit_1\": DATA_DIR / \"train_deposit_1.parquet\",\n",
    "    \"other_1\": DATA_DIR / \"train_other_1.parquet\",\n",
    "    \"tax_registry_a_1\": DATA_DIR / \"train_tax_registry_a_1.parquet\",\n",
    "    \"tax_registry_b_1\": DATA_DIR / \"train_tax_registry_b_1.parquet\",\n",
    "    \"tax_registry_c_1\": DATA_DIR / \"train_tax_registry_c_1.parquet\",\n",
    "}\n",
    "\n",
    "TEST_DATA_DIR = Path(\"home_credit_data/parquet_files/test\")\n",
    "TEST_TABLES = {\n",
    "        \"base\": TEST_DATA_DIR / \"test_base.parquet\",\n",
    "        \"static_0_0\": TEST_DATA_DIR / \"test_static_0_0.parquet\",\n",
    "        \"static_0_1\": TEST_DATA_DIR / \"test_static_0_1.parquet\",\n",
    "        \"static_cb_0\": TEST_DATA_DIR / \"test_static_cb_0.parquet\",\n",
    "        \"person_1\": TEST_DATA_DIR / \"test_person_1.parquet\",\n",
    "        \"person_2\": TEST_DATA_DIR / \"test_person_2.parquet\",\n",
    "        \"applprev_1_0\": TEST_DATA_DIR / \"test_applprev_1_0.parquet\",\n",
    "        \"applprev_1_1\": TEST_DATA_DIR / \"test_applprev_1_1.parquet\",\n",
    "        \"applprev_2\": TEST_DATA_DIR / \"test_applprev_2.parquet\",\n",
    "        \"credit_bureau_a_1_0\": TEST_DATA_DIR / \"test_credit_bureau_a_1_0.parquet\",\n",
    "        \"credit_bureau_a_1_1\": TEST_DATA_DIR / \"test_credit_bureau_a_1_1.parquet\",\n",
    "        \"credit_bureau_a_1_2\": TEST_DATA_DIR / \"test_credit_bureau_a_1_2.parquet\",\n",
    "        \"credit_bureau_a_1_3\": TEST_DATA_DIR / \"test_credit_bureau_a_1_3.parquet\",\n",
    "        \"credit_bureau_a_2_0\": TEST_DATA_DIR / \"test_credit_bureau_a_2_0.parquet\",\n",
    "        \"credit_bureau_a_2_1\": TEST_DATA_DIR / \"test_credit_bureau_a_2_1.parquet\",\n",
    "        \"credit_bureau_a_2_2\": TEST_DATA_DIR / \"test_credit_bureau_a_2_2.parquet\",\n",
    "        \"credit_bureau_a_2_3\": TEST_DATA_DIR / \"test_credit_bureau_a_2_3.parquet\",\n",
    "        \"credit_bureau_a_2_4\": TEST_DATA_DIR / \"test_credit_bureau_a_2_4.parquet\",\n",
    "        \"credit_bureau_a_2_5\": TEST_DATA_DIR / \"test_credit_bureau_a_2_5.parquet\",\n",
    "        \"credit_bureau_a_2_6\": TEST_DATA_DIR / \"test_credit_bureau_a_2_6.parquet\",\n",
    "        \"credit_bureau_a_2_7\": TEST_DATA_DIR / \"test_credit_bureau_a_2_7.parquet\",\n",
    "        \"credit_bureau_a_2_8\": TEST_DATA_DIR / \"test_credit_bureau_a_2_8.parquet\",\n",
    "        \"credit_bureau_a_2_9\": TEST_DATA_DIR / \"test_credit_bureau_a_2_9.parquet\",\n",
    "        \"credit_bureau_a_2_10\": TEST_DATA_DIR / \"test_credit_bureau_a_2_10.parquet\",\n",
    "        \"credit_bureau_b_1\": TEST_DATA_DIR / \"test_credit_bureau_b_1.parquet\",\n",
    "        \"credit_bureau_b_2\": TEST_DATA_DIR / \"test_credit_bureau_b_2.parquet\",\n",
    "        \"debitcard_1\": TEST_DATA_DIR / \"test_debitcard_1.parquet\",\n",
    "        \"deposit_1\": TEST_DATA_DIR / \"test_deposit_1.parquet\",       \n",
    "        \"other_1\": TEST_DATA_DIR / \"test_other_1.parquet\",\n",
    "        \"tax_registry_a_1\": TEST_DATA_DIR / \"test_tax_registry_a_1.parquet\",\n",
    "        \"tax_registry_b_1\": TEST_DATA_DIR / \"test_tax_registry_b_1.parquet\",\n",
    "        \"tax_registry_c_1\": TEST_DATA_DIR / \"test_tax_registry_c_1.parquet\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8040109c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory(df: pl.DataFrame, verbose: bool = True) -> pl.DataFrame:\n",
    "\n",
    "    start_mem = df.estimated_size(\"mb\")\n",
    "\n",
    "    cast_exprs = []\n",
    "\n",
    "    for col, dtype in df.schema.items():\n",
    "\n",
    "        # ---- Integers\n",
    "        if dtype == pl.Int64:\n",
    "            col_min = df[col].min()\n",
    "            col_max = df[col].max()\n",
    "\n",
    "            if col_min >= -128 and col_max <= 127:\n",
    "                cast_exprs.append(pl.col(col).cast(pl.Int8))\n",
    "            elif col_min >= -32768 and col_max <= 32767:\n",
    "                cast_exprs.append(pl.col(col).cast(pl.Int16))\n",
    "            elif col_min >= -2147483648 and col_max <= 2147483647:\n",
    "                cast_exprs.append(pl.col(col).cast(pl.Int32))\n",
    "\n",
    "        # ---- Floats\n",
    "        elif dtype == pl.Float64:\n",
    "            cast_exprs.append(pl.col(col).cast(pl.Float32))\n",
    "\n",
    "        # ---- Strings (optional: convert low-cardinality to categorical)\n",
    "        elif dtype == pl.Utf8:\n",
    "            n_unique = df[col].n_unique()\n",
    "            if n_unique < 0.5 * len(df):\n",
    "                cast_exprs.append(pl.col(col).cast(pl.Categorical))\n",
    "\n",
    "    if cast_exprs:\n",
    "        df = df.with_columns(cast_exprs)\n",
    "\n",
    "    end_mem = df.estimated_size(\"mb\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Memory before: {start_mem:.2f} MB\")\n",
    "        print(f\"Memory after : {end_mem:.2f} MB\")\n",
    "        print(f\"Reduced by    : {(start_mem - end_mem):.2f} MB \"\n",
    "              f\"({100*(start_mem - end_mem)/start_mem:.1f}%)\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e37b607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory before: 34.94 MB\n",
      "Memory after : 8.74 MB\n",
      "Reduced by    : 26.21 MB (75.0%)\n",
      "Memory before: 393.91 MB\n",
      "Memory after : 327.24 MB\n",
      "Reduced by    : 66.67 MB (16.9%)\n",
      "Memory before: 2025.64 MB\n",
      "Memory after : 1444.19 MB\n",
      "Reduced by    : 581.45 MB (28.7%)\n",
      "Memory before: 1054.20 MB\n",
      "Memory after : 752.09 MB\n",
      "Reduced by    : 302.11 MB (28.7%)\n",
      "Memory before: 1004.32 MB\n",
      "Memory after : 612.81 MB\n",
      "Reduced by    : 391.50 MB (39.0%)\n",
      "Memory before: 4.09 MB\n",
      "Memory after : 3.22 MB\n",
      "Reduced by    : 0.88 MB (21.4%)\n",
      "Memory before: 5459.21 MB\n",
      "Memory after : 5459.21 MB\n",
      "Reduced by    : 0.00 MB (0.0%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1526659, 946)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "import gc\n",
    "\n",
    "\n",
    "train_base = pl.read_parquet(TABLES[\"base\"])\n",
    "train_base = Pipeline.set_table_dtypes(None, train_base)\n",
    "train_base = Pipeline.handle_dates(None, train_base)\n",
    "train_base = reduce_memory(train_base)\n",
    "\n",
    "train_merged = train_base\n",
    "# merge all tables with depth 1\n",
    "tables = [\"person_1\", \"static_0_0\", \"static_0_1\", \"static_cb_0\", \"other_1\"]\n",
    "for table in tables:\n",
    "    table_data = pl.read_parquet(TABLES[table])\n",
    "    table_data = Pipeline.set_table_dtypes(None, table_data) \n",
    "    table_data = Pipeline.handle_dates(None, table_data)\n",
    "    table_data = (table_data\n",
    "        .group_by(\"case_id\")\n",
    "        .agg(Aggregator.get_exprs(table_data, prefix=table))\n",
    "    )\n",
    "    table_data = reduce_memory(table_data)\n",
    "    train_merged = train_merged.join(table_data, on=\"case_id\", how=\"left\")\n",
    "    del table_data\n",
    "    gc.collect()\n",
    "\n",
    "train_merged = reduce_memory(train_merged)\n",
    "train_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a71845b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1526659\n",
      "5459.212637901306\n"
     ]
    }
   ],
   "source": [
    "print(train_base[\"case_id\"].n_unique())\n",
    "print(train_merged.estimated_size(\"mb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "073aed61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1526659, 667)\n"
     ]
    }
   ],
   "source": [
    "n_rows = train_merged.shape[0]\n",
    "\n",
    "cols_keep = [\n",
    "    c for c in train_merged.columns\n",
    "    if train_merged[c].null_count() / n_rows < 0.8\n",
    "]\n",
    "\n",
    "train_merged = train_merged.select(cols_keep)\n",
    "\n",
    "print(train_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67e4cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    c for c in train_merged.columns\n",
    "    if train_merged[c].dtype in (pl.Float32, pl.Float64, pl.Int32, pl.Int64)\n",
    "]\n",
    "\n",
    "train_merged = train_merged.select(numeric_cols + [\"target\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fc94f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1526659, 537)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "558bab19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1526659, 536)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = train_merged[\"target\"].to_numpy()\n",
    "X = train_merged.drop(\"target\").to_numpy().astype(np.float32)\n",
    "feature_columns = train_merged.drop(\"target\").columns\n",
    "\n",
    "del train_merged\n",
    "gc.collect()\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b54ad689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=800,           \n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    tree_method=\"hist\",         \n",
    "    eval_metric=\"auc\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# preds = model.predict_proba(X_valid)[:, 1]\n",
    "# auc = roc_auc_score(y_valid, preds)\n",
    "\n",
    "# print(\"Validation AUC:\", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bb3400",
   "metadata": {},
   "source": [
    "# Validation AUC: 0.8052800470575214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532dbb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "# # Train on full datasets\n",
    "# model.fit(X, y)\n",
    "\n",
    "# joblib.dump(model, \"xgb_full_model.pkl\")\n",
    "# joblib.dump(feature_columns, \"feature_columns.pkl\")\n",
    "\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b59cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory before: 0.00 MB\n",
      "Memory after : 0.00 MB\n",
      "Reduced by    : 0.00 MB (17.7%)\n",
      "Memory before: 0.02 MB\n",
      "Memory after : 0.01 MB\n",
      "Reduced by    : 0.01 MB (27.9%)\n",
      "Memory before: 0.02 MB\n",
      "Memory after : 0.01 MB\n",
      "Reduced by    : 0.01 MB (27.7%)\n",
      "Memory before: 0.01 MB\n",
      "Memory after : 0.00 MB\n",
      "Reduced by    : 0.00 MB (40.3%)\n",
      "Memory before: 0.00 MB\n",
      "Memory after : 0.00 MB\n",
      "Reduced by    : 0.00 MB (21.4%)\n",
      "['target']\n"
     ]
    }
   ],
   "source": [
    "test_merged = pl.read_parquet(TEST_TABLES[\"base\"])\n",
    "\n",
    "tables = [\"person_1\", \"static_0_0\", \"static_0_1\", \"static_cb_0\", \"other_1\"]\n",
    "for table in tables:\n",
    "    table_data = pl.read_parquet(TEST_TABLES[table])\n",
    "    table_data = Pipeline.set_table_dtypes(None, table_data) \n",
    "    table_data = Pipeline.handle_dates(None, table_data)\n",
    "    table_data = (table_data\n",
    "        .group_by(\"case_id\")\n",
    "        .agg(Aggregator.get_exprs(table_data, prefix=table))\n",
    "    )\n",
    "    table_data = reduce_memory(table_data)\n",
    "    test_merged = test_merged.join(table_data, on=\"case_id\", how=\"left\")\n",
    "    del table_data\n",
    "    gc.collect()\n",
    "\n",
    "test_merged.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c7908cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (10, 536)\n",
      "Expected features: 536\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "model = joblib.load(\"xgb_full_model.pkl\")\n",
    "feature_columns = joblib.load(\"feature_columns.pkl\")\n",
    "\n",
    "common_features = [c for c in feature_columns if c in test_merged.columns]\n",
    "\n",
    "\n",
    "X_test = (\n",
    "    test_merged\n",
    "    .select(common_features)        # ensure correct order\n",
    "    .to_numpy()\n",
    "    .astype(np.float32)\n",
    ")\n",
    "\n",
    "print(\"Test shape:\", X_test.shape)\n",
    "print(\"Expected features:\", len(feature_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28b19844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_preds = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_preds = np.asarray(test_preds, dtype=float)\n",
    "test_preds = np.nan_to_num(test_preds, nan=0.5, posinf=1.0, neginf=0.0)\n",
    "test_preds = np.clip(test_preds, 0.0, 1.0)\n",
    "\n",
    "print(\"Prediction shape:\", test_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fffc15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved successfully!\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"case_id\": test_merged[\"case_id\"].to_numpy(),\n",
    "    \"score\": test_preds\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission saved successfully!\")\n",
    "\n",
    "del model, feature_columns, X_test, test_preds, submission\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9dc8a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
