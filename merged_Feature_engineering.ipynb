{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merged Feature Engineering\n",
    "\n",
    "## Task Checklist\n",
    "\n",
    "1. **Aggregate depth=1 and depth=2 tables (max, min)** - DONE\n",
    "   - MUST_AGG tables aggregated with Polars, incremental AUC evaluation\n",
    "2. **Split data into Applicant vs others (num_group1)** - NOT DONE\n",
    "   - Person tables tested but dropped (reduced AUC); no applicant/others split implemented\n",
    "3. **Active and closed contracts** - DONE\n",
    "   - Status-based + date-based logic in `build_contract_features()`\n",
    "4. **Time-windowed aggregations** - DONE\n",
    "   - Default windows: <=1y, 1-3y, >3y; custom windows for ap1w: <=0.5y, 0.5-2y, >2y\n",
    "5. **DPD-conditional aggregations** - DONE\n",
    "   - DPD>=30 and DPD>=90 counts crossed with active/closed status\n",
    "6. **Aggregate redundancy from multiple tables** - NOT DONE\n",
    "   - No shard deduplication across table shards (e.g. credit_bureau_a_1_0 through _3)\n",
    "7. **StratifiedGroupKFold with WEEK_NUM as groups** - PARTIAL\n",
    "   - Rolling time splits used instead (cuts at WEEK_NUM 50, 60, 70); arguably better for stability metric\n",
    "8. **Remove features that fluctuate a lot, rank feature importance** - DONE\n",
    "   - Incremental block evaluation: add block, check AUC delta, keep or drop; rolling stability validation\n",
    "\n",
    "---\n",
    "\n",
    "## Current state: 74 features across 5 retained blocks\n",
    "\n",
    "- cb1 (credit_bureau_b_1) - active/closed contracts, DPD, time windows\n",
    "- ap1w (applprev_1_1) - custom time windows (<=0.5y, 0.5-2y, >2y)\n",
    "- dep (deposit_1) - active/closed deposits, time windows\n",
    "- taxa (tax_registry_a_1) - record presence, time windows\n",
    "- ap2 (applprev_2) - application history counts\n",
    "\n",
    "## Still missing (to be built)\n",
    "\n",
    "- Static tables (static_0_0, static_0_1, static_cb_0) - 1:1 joins, easiest features\n",
    "- DANGEROUS tables (credit_bureau_a shards) - largest data source, untouched\n",
    "- Applicant vs others split from person tables\n",
    "- Shard deduplication\n",
    "- other_1, tax_registry_b_1, tax_registry_c_1, credit_bureau_b_2"
   ],
   "id": "cell-0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ],
   "id": "cell-1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# UPDATE THIS PATH to your local data directory\n",
    "DATA_DIR = Path(\"home_credit_data/csv_files/train\")\n",
    "\n",
    "TABLES = {\n",
    "    \"base\": DATA_DIR / \"train_base.csv\",\n",
    "    \"applprev_1_0\": DATA_DIR / \"train_applprev_1_0.csv\",\n",
    "    \"applprev_1_1\": DATA_DIR / \"train_applprev_1_1.csv\",\n",
    "    \"applprev_2\": DATA_DIR / \"train_applprev_2.csv\",\n",
    "    \"credit_bureau_b_1\": DATA_DIR / \"train_credit_bureau_b_1.csv\",\n",
    "    \"deposit_1\": DATA_DIR / \"train_deposit_1.csv\",\n",
    "    \"tax_registry_a_1\": DATA_DIR / \"train_tax_registry_a_1.csv\",\n",
    "}"
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Load base table"
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pl.read_csv(TABLES[\"base\"])\n",
    "\n",
    "base_dates = (\n",
    "    base.select([\"case_id\", \"date_decision\"])\n",
    "    .with_columns(pl.col(\"date_decision\").str.strptime(pl.Date, strict=False))\n",
    ")\n",
    "\n",
    "print(f\"Base shape: {base.shape}\")\n",
    "print(f\"Target rate: {base['target'].mean():.4f}\")\n",
    "base.head()"
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Feature building functions\n",
    "\n",
    "Leak-safe aggregation: only uses records known at decision time (age_years >= 0).\n",
    "Produces active/closed counts, DPD conditional counts, and time-windowed counts."
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_contract_features(\n",
    "    table_path: Path,\n",
    "    prefix: str,\n",
    "    base_dates: pl.DataFrame,\n",
    "    event_date_cols: list[str],\n",
    "    dpd_col: str | None = None,\n",
    "    active_flag_expr: pl.Expr | None = None,\n",
    "    closed_flag_expr: pl.Expr | None = None,\n",
    "):\n",
    "    df = pl.read_csv(table_path).join(base_dates, on=\"case_id\", how=\"left\")\n",
    "\n",
    "    parse_exprs = [pl.col(c).str.strptime(pl.Date, strict=False).alias(c) for c in event_date_cols if c in df.columns]\n",
    "    cast_exprs = [pl.col(dpd_col).cast(pl.Float64, strict=False).alias(dpd_col)] if (dpd_col is not None and dpd_col in df.columns) else []\n",
    "    df = df.with_columns(parse_exprs + cast_exprs)\n",
    "\n",
    "    available_dates = [pl.col(c) for c in event_date_cols if c in df.columns]\n",
    "    if len(available_dates) > 0:\n",
    "        df = df.with_columns(pl.coalesce(available_dates).alias(\"event_date\"))\n",
    "        df = df.with_columns(((pl.col(\"date_decision\") - pl.col(\"event_date\")).dt.total_days() / 365.25).alias(\"age_years\"))\n",
    "        known_mask = (pl.col(\"age_years\") >= 0)\n",
    "    else:\n",
    "        df = df.with_columns([\n",
    "            pl.lit(None).cast(pl.Date).alias(\"event_date\"),\n",
    "            pl.lit(None).cast(pl.Float64).alias(\"age_years\"),\n",
    "        ])\n",
    "        known_mask = pl.lit(True)\n",
    "\n",
    "    if active_flag_expr is None:\n",
    "        active_flag_expr = pl.lit(False)\n",
    "    if closed_flag_expr is None:\n",
    "        closed_flag_expr = pl.lit(False)\n",
    "\n",
    "    df = df.with_columns([\n",
    "        active_flag_expr.fill_null(False).alias(\"is_active\"),\n",
    "        closed_flag_expr.fill_null(False).alias(\"is_closed\"),\n",
    "    ])\n",
    "\n",
    "    if dpd_col is not None and dpd_col in df.columns:\n",
    "        df = df.with_columns([\n",
    "            (pl.col(dpd_col) >= 30).fill_null(False).alias(\"dpd30\"),\n",
    "            (pl.col(dpd_col) >= 90).fill_null(False).alias(\"dpd90\"),\n",
    "        ])\n",
    "    else:\n",
    "        df = df.with_columns([\n",
    "            pl.lit(False).alias(\"dpd30\"),\n",
    "            pl.lit(False).alias(\"dpd90\"),\n",
    "        ])\n",
    "\n",
    "    agg = df.group_by(\"case_id\").agg([\n",
    "        pl.len().alias(f\"{prefix}_row_count_all\"),\n",
    "        known_mask.sum().alias(f\"{prefix}_known_count\"),\n",
    "\n",
    "        (known_mask & pl.col(\"is_active\")).sum().alias(f\"{prefix}_active_count_all\"),\n",
    "        (known_mask & pl.col(\"is_closed\")).sum().alias(f\"{prefix}_closed_count_all\"),\n",
    "\n",
    "        (known_mask & pl.col(\"is_active\") & pl.col(\"dpd30\")).sum().alias(f\"{prefix}_active_dpd30_count_all\"),\n",
    "        (known_mask & pl.col(\"is_active\") & pl.col(\"dpd90\")).sum().alias(f\"{prefix}_active_dpd90_count_all\"),\n",
    "        (known_mask & pl.col(\"is_closed\") & pl.col(\"dpd30\")).sum().alias(f\"{prefix}_closed_dpd30_count_all\"),\n",
    "        (known_mask & pl.col(\"is_closed\") & pl.col(\"dpd90\")).sum().alias(f\"{prefix}_closed_dpd90_count_all\"),\n",
    "\n",
    "        (known_mask & pl.col(\"is_active\") & (pl.col(\"age_years\") <= 1)).sum().alias(f\"{prefix}_active_count_le1y\"),\n",
    "        (known_mask & pl.col(\"is_closed\") & (pl.col(\"age_years\") <= 1)).sum().alias(f\"{prefix}_closed_count_le1y\"),\n",
    "\n",
    "        (known_mask & pl.col(\"is_active\") & (pl.col(\"age_years\") > 1) & (pl.col(\"age_years\") <= 3)).sum().alias(f\"{prefix}_active_count_1to3y\"),\n",
    "        (known_mask & pl.col(\"is_closed\") & (pl.col(\"age_years\") > 1) & (pl.col(\"age_years\") <= 3)).sum().alias(f\"{prefix}_closed_count_1to3y\"),\n",
    "\n",
    "        (known_mask & pl.col(\"is_active\") & (pl.col(\"age_years\") > 3)).sum().alias(f\"{prefix}_active_count_gt3y\"),\n",
    "        (known_mask & pl.col(\"is_closed\") & (pl.col(\"age_years\") > 3)).sum().alias(f\"{prefix}_closed_count_gt3y\"),\n",
    "    ])\n",
    "\n",
    "    agg = agg.with_columns([\n",
    "        pl.when(pl.col(f\"{prefix}_active_count_all\") > 0)\n",
    "        .then(pl.col(f\"{prefix}_active_dpd30_count_all\") / pl.col(f\"{prefix}_active_count_all\"))\n",
    "        .otherwise(0.0)\n",
    "        .alias(f\"{prefix}_active_dpd30_rate\"),\n",
    "\n",
    "        pl.when(pl.col(f\"{prefix}_closed_count_all\") > 0)\n",
    "        .then(pl.col(f\"{prefix}_closed_dpd30_count_all\") / pl.col(f\"{prefix}_closed_count_all\"))\n",
    "        .otherwise(0.0)\n",
    "        .alias(f\"{prefix}_closed_dpd30_rate\"),\n",
    "    ])\n",
    "\n",
    "    return agg"
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_contract_features_custom_windows(\n",
    "    table_path: Path,\n",
    "    prefix: str,\n",
    "    base_dates: pl.DataFrame,\n",
    "    event_date_cols: list[str],\n",
    "    windows=((0,1),(1,3),(3,999)),\n",
    "    dpd_col: str | None = None,\n",
    "    active_flag_expr: pl.Expr | None = None,\n",
    "    closed_flag_expr: pl.Expr | None = None,\n",
    "):\n",
    "    df = pl.read_csv(table_path).join(base_dates, on=\"case_id\", how=\"left\")\n",
    "\n",
    "    parse_exprs = [pl.col(c).str.strptime(pl.Date, strict=False).alias(c) for c in event_date_cols if c in df.columns]\n",
    "    cast_exprs = [pl.col(dpd_col).cast(pl.Float64, strict=False).alias(dpd_col)] if (dpd_col is not None and dpd_col in df.columns) else []\n",
    "    df = df.with_columns(parse_exprs + cast_exprs)\n",
    "\n",
    "    dates = [pl.col(c) for c in event_date_cols if c in df.columns]\n",
    "    if len(dates) > 0:\n",
    "        df = df.with_columns([\n",
    "            pl.coalesce(dates).alias(\"event_date\"),\n",
    "            ((pl.col(\"date_decision\") - pl.coalesce(dates)).dt.total_days() / 365.25).alias(\"age_years\"),\n",
    "        ])\n",
    "        known = (pl.col(\"age_years\") >= 0)\n",
    "    else:\n",
    "        df = df.with_columns([pl.lit(None).cast(pl.Float64).alias(\"age_years\")])\n",
    "        known = pl.lit(True)\n",
    "\n",
    "    if active_flag_expr is None:\n",
    "        active_flag_expr = pl.lit(False)\n",
    "    if closed_flag_expr is None:\n",
    "        closed_flag_expr = pl.lit(False)\n",
    "\n",
    "    df = df.with_columns([\n",
    "        active_flag_expr.fill_null(False).alias(\"is_active\"),\n",
    "        closed_flag_expr.fill_null(False).alias(\"is_closed\"),\n",
    "    ])\n",
    "\n",
    "    aggs = [\n",
    "        pl.len().alias(f\"{prefix}_row_count_all\"),\n",
    "        (known & pl.col(\"is_active\")).sum().alias(f\"{prefix}_active_count_all\"),\n",
    "        (known & pl.col(\"is_closed\")).sum().alias(f\"{prefix}_closed_count_all\"),\n",
    "    ]\n",
    "\n",
    "    for lo, hi in windows:\n",
    "        tag = f\"{lo}to{hi}\" if hi < 999 else f\"gt{lo}\"\n",
    "        cond = (pl.col(\"age_years\") > lo) & (pl.col(\"age_years\") <= hi) if hi < 999 else (pl.col(\"age_years\") > lo)\n",
    "        aggs += [\n",
    "            (known & pl.col(\"is_active\") & cond).sum().alias(f\"{prefix}_active_count_{tag}\"),\n",
    "            (known & pl.col(\"is_closed\") & cond).sum().alias(f\"{prefix}_closed_count_{tag}\"),\n",
    "        ]\n",
    "\n",
    "    return df.group_by(\"case_id\").agg(aggs)"
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Build retained feature blocks\n",
    "\n",
    "5 blocks retained after incremental AUC evaluation:\n",
    "- cb1: credit_bureau_b_1\n",
    "- ap1w: applprev_1_1 (custom windows)\n",
    "- dep: deposit_1\n",
    "- taxa: tax_registry_a_1\n",
    "- ap2: applprev_2"
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb1: credit_bureau_b_1\n",
    "cb1_agg = build_contract_features(\n",
    "    table_path=TABLES[\"credit_bureau_b_1\"],\n",
    "    prefix=\"cb1\",\n",
    "    base_dates=base_dates,\n",
    "    event_date_cols=[\"lastupdate_260D\", \"contractdate_551D\"],\n",
    "    dpd_col=\"dpd_550P\",\n",
    "    active_flag_expr=(pl.col(\"contractmaturitydate_151D\").str.strptime(pl.Date, strict=False) >= pl.col(\"date_decision\")),\n",
    "    closed_flag_expr=(pl.col(\"contractmaturitydate_151D\").str.strptime(pl.Date, strict=False) < pl.col(\"date_decision\")),\n",
    ")\n",
    "print(f\"cb1: {cb1_agg.shape}\")"
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ap1w: applprev_1_1 with best window scheme (<=0.5y, 0.5-2y, >2y)\n",
    "ap1w_agg = build_contract_features_custom_windows(\n",
    "    table_path=TABLES[\"applprev_1_1\"],\n",
    "    prefix=\"ap1w\",\n",
    "    base_dates=base_dates,\n",
    "    event_date_cols=[\"dateactivated_425D\", \"approvaldate_319D\", \"creationdate_885D\"],\n",
    "    windows=((0, 0.5), (0.5, 2), (2, 999)),\n",
    "    dpd_col=None,\n",
    "    active_flag_expr=pl.col(\"status_219L\").is_in([\"A\"]),\n",
    "    closed_flag_expr=pl.col(\"status_219L\").is_in([\"D\", \"K\", \"T\"]),\n",
    ")\n",
    "print(f\"ap1w: {ap1w_agg.shape}\")"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dep: deposit_1\n",
    "dep_agg = build_contract_features(\n",
    "    table_path=TABLES[\"deposit_1\"],\n",
    "    prefix=\"dep\",\n",
    "    base_dates=base_dates,\n",
    "    event_date_cols=[\"openingdate_313D\", \"contractenddate_991D\"],\n",
    "    dpd_col=None,\n",
    "    active_flag_expr=(pl.col(\"contractenddate_991D\") >= pl.col(\"date_decision\")),\n",
    "    closed_flag_expr=(pl.col(\"contractenddate_991D\") < pl.col(\"date_decision\")),\n",
    ")\n",
    "print(f\"dep: {dep_agg.shape}\")"
   ],
   "id": "cell-11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxa: tax_registry_a_1\n",
    "taxa_agg = build_contract_features(\n",
    "    table_path=TABLES[\"tax_registry_a_1\"],\n",
    "    prefix=\"taxa\",\n",
    "    base_dates=base_dates,\n",
    "    event_date_cols=[\"recorddate_4527225D\"],\n",
    "    dpd_col=None,\n",
    "    active_flag_expr=pl.lit(True),\n",
    "    closed_flag_expr=pl.lit(False),\n",
    ")\n",
    "print(f\"taxa: {taxa_agg.shape}\")"
   ],
   "id": "cell-12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ap2: applprev_2 (no event dates or DPD, just row counts)\n",
    "ap2 = pl.read_csv(TABLES[\"applprev_2\"]).join(base_dates, on=\"case_id\", how=\"left\")\n",
    "\n",
    "ap2_agg = (\n",
    "    ap2.group_by(\"case_id\").agg([\n",
    "        pl.len().alias(\"ap2_row_count_all\"),\n",
    "        pl.len().alias(\"ap2_known_count\"),\n",
    "        pl.len().alias(\"ap2_active_count_all\"),\n",
    "        pl.lit(0).sum().cast(pl.Int64).alias(\"ap2_closed_count_all\"),\n",
    "        pl.lit(0).sum().cast(pl.Int64).alias(\"ap2_active_dpd30_count_all\"),\n",
    "        pl.lit(0).sum().cast(pl.Int64).alias(\"ap2_active_dpd90_count_all\"),\n",
    "        pl.lit(0).sum().cast(pl.Int64).alias(\"ap2_closed_dpd30_count_all\"),\n",
    "        pl.lit(0).sum().cast(pl.Int64).alias(\"ap2_closed_dpd90_count_all\"),\n",
    "        pl.lit(0).sum().cast(pl.Int64).alias(\"ap2_active_count_le1y\"),\n",
    "        pl.lit(0).sum().cast(pl.Int64).alias(\"ap2_closed_count_le1y\"),\n",
    "        pl.lit(0).sum().cast(pl.Int64).alias(\"ap2_active_count_1to3y\"),\n",
    "        pl.lit(0).sum().cast(pl.Int64).alias(\"ap2_closed_count_1to3y\"),\n",
    "        pl.lit(0).sum().cast(pl.Int64).alias(\"ap2_active_count_gt3y\"),\n",
    "        pl.lit(0).sum().cast(pl.Int64).alias(\"ap2_closed_count_gt3y\"),\n",
    "    ])\n",
    "    .with_columns([\n",
    "        pl.lit(0.0).alias(\"ap2_active_dpd30_rate\"),\n",
    "        pl.lit(0.0).alias(\"ap2_closed_dpd30_rate\"),\n",
    "    ])\n",
    ")\n",
    "print(f\"ap2: {ap2_agg.shape}\")"
   ],
   "id": "cell-13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Merge all blocks into base"
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = (\n",
    "    base\n",
    "    .join(cb1_agg, on=\"case_id\", how=\"left\")\n",
    "    .join(ap1w_agg, on=\"case_id\", how=\"left\")\n",
    "    .join(dep_agg, on=\"case_id\", how=\"left\")\n",
    "    .join(taxa_agg, on=\"case_id\", how=\"left\")\n",
    "    .join(ap2_agg, on=\"case_id\", how=\"left\")\n",
    "    .with_columns([\n",
    "        pl.col(\"^cb1_.*$\").fill_null(0),\n",
    "        pl.col(\"^ap1w_.*$\").fill_null(0),\n",
    "        pl.col(\"^dep_.*$\").fill_null(0),\n",
    "        pl.col(\"^taxa_.*$\").fill_null(0),\n",
    "        pl.col(\"^ap2_.*$\").fill_null(0),\n",
    "    ])\n",
    ")\n",
    "\n",
    "feature_cols = [c for c in model_df.columns if c not in [\"case_id\", \"date_decision\", \"MONTH\", \"target\"]]\n",
    "print(f\"Final shape: {model_df.shape}\")\n",
    "print(f\"Feature count: {len(feature_cols)}\")\n",
    "print(f\"Features: {feature_cols}\")"
   ],
   "id": "cell-15"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Evaluation helpers"
   ],
   "id": "cell-16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_auc_for_cut(df, feature_cols, cut_week):\n",
    "    tr = df.filter(pl.col(\"WEEK_NUM\") <= cut_week)\n",
    "    va = df.filter(pl.col(\"WEEK_NUM\") > cut_week)\n",
    "\n",
    "    Xtr = tr.select(feature_cols).to_pandas()\n",
    "    ytr = tr[\"target\"].to_pandas()\n",
    "    Xva = va.select(feature_cols).to_pandas()\n",
    "    yva = va[\"target\"].to_pandas()\n",
    "\n",
    "    clf = HistGradientBoostingClassifier(max_depth=6, learning_rate=0.05, max_iter=200, random_state=42)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    p = clf.predict_proba(Xva)[:, 1]\n",
    "    return roc_auc_score(yva, p)\n",
    "\n",
    "\n",
    "def eval_stability(df, feature_cols, cuts=(50, 60, 70), label=\"model\"):\n",
    "    rows = []\n",
    "    for c in cuts:\n",
    "        auc = run_auc_for_cut(df, feature_cols, c)\n",
    "        rows.append({\"model\": label, \"cut_week\": c, \"auc\": auc})\n",
    "    out = pd.DataFrame(rows)\n",
    "    summary = {\n",
    "        \"model\": label,\n",
    "        \"mean_auc\": out[\"auc\"].mean(),\n",
    "        \"std_auc\": out[\"auc\"].std(ddof=0),\n",
    "        \"min_auc\": out[\"auc\"].min(),\n",
    "        \"max_auc\": out[\"auc\"].max(),\n",
    "    }\n",
    "    return out, pd.DataFrame([summary])"
   ],
   "id": "cell-17"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Validate"
   ],
   "id": "cell-18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail, summary = eval_stability(model_df, feature_cols, cuts=(50, 60, 70), label=\"darren_74_features\")\n",
    "print(detail)\n",
    "print()\n",
    "print(summary)"
   ],
   "id": "cell-19"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
